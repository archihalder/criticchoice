{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test.ft.txt.bz2', 'train.ft.txt.bz2']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import fasttext\n",
    "import bz2\n",
    "import csv\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600000\n"
     ]
    }
   ],
   "source": [
    "# Load the training data \n",
    "data = bz2.BZ2File(\"../input/train.ft.txt.bz2\")\n",
    "data = data.readlines()\n",
    "data = [x.decode('utf-8') for x in data]\n",
    "print(len(data)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"__label__2 The best soundtrack ever to anything.: I'm reading a lot of reviews saying that this is the best 'game soundtrack' and I figured that I'd write a review to disagree a bit. This in my opinino is Yasunori Mitsuda's ultimate masterpiece. The music is timeless and I'm been listening to it for years now and its beauty simply refuses to fade.The price tag on this is pretty staggering I must say, but if you are going to buy any cd for this much money, this is the only one that I feel would be worth every penny.\\n\",\n",
       " '__label__2 Amazing!: This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\\n',\n",
       " \"__label__2 Excellent Soundtrack: I truly like this soundtrack and I enjoy video game music. I have played this game and most of the music on here I enjoy and it's truly relaxing and peaceful.On disk one. my favorites are Scars Of Time, Between Life and Death, Forest Of Illusion, Fortress of Ancient Dragons, Lost Fragment, and Drowned Valley.Disk Two: The Draggons, Galdorb - Home, Chronomantique, Prisoners of Fate, Gale, and my girlfriend likes ZelbessDisk Three: The best of the three. Garden Of God, Chronopolis, Fates, Jellyfish sea, Burning Orphange, Dragon's Prayer, Tower Of Stars, Dragon God, and Radical Dreamers - Unstealable Jewel.Overall, this is a excellent soundtrack and should be brought by those that like video game music.Xander Cross\\n\",\n",
       " \"__label__2 Remember, Pull Your Jaw Off The Floor After Hearing it: If you've played the game, you know how divine the music is! Every single song tells a story of the game, it's that good! The greatest songs are without a doubt, Chrono Cross: Time's Scar, Magical Dreamers: The Wind, The Stars, and the Sea and Radical Dreamers: Unstolen Jewel. (Translation varies) This music is perfect if you ask me, the best it can be. Yasunori Mitsuda just poured his heart on and wrote it down on paper.\\n\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3.6mil rows! Lets inspect a few records to see the format and get a feel for the data\n",
    "data[1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep and modelling\n",
    "A slight inconvenience with the FastText model is the need to save the dataset into a text file. And the annoying encoding of the \"____label__ ____#__\". Basically, the target and the text is all in the same cell. They are distinguished by the prefix of '____label__ ____#__'. Lets say if have 2 labels and one is 'Ham' and the other 'Spam', then your labels would be '____label__ ____Ham__' and '____label__ ____Spam__'. You can include as many labels as well, not just 2.   \n",
    "\n",
    "Thankfully, this dataset has already been formated in that way as you can see from the first 5 records I printed out. We just need to write it out to disk. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__label__1', '__label__2'] are the labels or targets the model is predicting\n"
     ]
    }
   ],
   "source": [
    "# Data Prep\n",
    "data = pd.DataFrame(data)\n",
    "data.to_csv(\"train.txt\", index=False, sep=' ', header=False, quoting=csv.QUOTE_NONE, quotechar=\"\", escapechar=\" \")\n",
    "\n",
    "# Modelling\n",
    "# This routine takes about 5 to 10 minutes \n",
    "model = fasttext.train_supervised('train.txt',label_prefix='__label__', thread=4, epoch = 10)\n",
    "print(model.labels, 'are the labels or targets the model is predicting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply predictions\n",
    "Ok after about 10 minutes or so, the model is finished. Now lets apply the predictions to the test dataset. Thankfully, we don't have to write out a physical text file to do the prediction. You could if you want to, but I'm just going to use the data object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400000 number of records in the test set\n",
      "['__label__2'] is the predicted label\n",
      "['__label__2'] is the probability score\n"
     ]
    }
   ],
   "source": [
    "# Load the test data \n",
    "test = bz2.BZ2File(\"../input/test.ft.txt.bz2\")\n",
    "test = test.readlines()\n",
    "test = [x.decode('utf-8') for x in test]\n",
    "print(len(test), 'number of records in the test set') \n",
    "\n",
    "# To run the predict function, we need to remove the __label__1 and __label__2 from the testset.  \n",
    "new = [w.replace('__label__2 ', '') for w in test]\n",
    "new = [w.replace('__label__1 ', '') for w in new]\n",
    "new = [w.replace('\\n', '') for w in new]\n",
    "\n",
    "# Use the predict function \n",
    "pred = model.predict(new)\n",
    "\n",
    "# check the first record outputs\n",
    "print(pred[0][0], 'is the predicted label')\n",
    "print(pred[0][1], 'is the probability score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation \n",
    "Ok so we have our predictions, now lets measure how well we have done? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.91725\n"
     ]
    }
   ],
   "source": [
    "# Lets recode the actual targets to 1's and 0's from both the test set and the actual predictions  \n",
    "labels = [0 if x.split(' ')[0] == '__label__1' else 1 for x in test]\n",
    "pred_labels = [0 if x == ['__label__1'] else 1 for x in pred[0]]\n",
    "\n",
    "# run the accuracy measure. \n",
    "print(roc_auc_score(labels, pred_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 91.7%\n",
    "91.7% absolute accuracy score with only just a few lines of code. Running the evaluation metric using the Probability score would yeild even higher scores but I wanted to keep it inline with the rest of the kernels so its a fair comparison. The most popular Kernel here is the CuDNNLSTM which yielded 93.7%\n",
    "\n",
    "Perhaps the most challenging bit about using FastText is just the slightly annoying data preparation step to encode the '__labels__'. Just like any data science projects, data prep is the hard yard. Otherwise, rest is pretty straight foward. I'll post another kernel on a different dataset in future and run through the processing steps to get the dataset into the correct format. And some other model tuning process.\n",
    "\n",
    "If you like this kernel please give me an upvote! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "1596be4e44985300faa7cd7a661d13a5120a17c2d5a547f653c01ea2a51fe323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
